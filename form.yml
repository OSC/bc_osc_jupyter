---
cluster: 
  - "owens"
  - "pitzer"
form:
  - bc_account
  - jupyterlab_switch
  - bc_num_hours
  - node_type
  - cuda_version
  - num_cores
  - version
  - bc_email_on_started
attributes:
  jupyterlab_switch:
    widget: "check_box"
    label: "Use JupyterLab instead of Jupyter Notebook?"
    help: |
      JupyterLab is the next generation of Jupyter, and is completely compatible with existing Jupyter Notebooks.
  num_cores:
    widget: "number_field"
    label: "Number of cores"
    value: 1
    help: |
      Number of cores on node type (4 GB per core unless requesting whole
      node). Leave blank if requesting full node.
    min: 1
    max: 28
    step: 1
  bc_account:
    label: "Project"
    help: "You can leave this blank if **not** in multiple projects."
  cuda_version:
    widget: "select"
    label: "CUDA Version"
    help: |
      CUDA is Nvidia's GPU-specific parallel computing framework. A GPU node
      is required to make use of this functionality.
    options:
      - [ "cuda/8.0.44",    "cuda/8.0.44"   ]
      - [ "cuda/8.0.61",    "cuda/8.0.61"   ]
      - [ "cuda/9.0.176",   "cuda/9.0.176"  ]
      - [ "cuda/9.1.85",    "cuda/9.1.85"   ]
      - [ "cuda/9.2.88",    "cuda/9.2.88"   ]
      - [ "cuda/10.0.130",  "cuda/10.0.130" ]
  node_type:
    widget: select
    label: "Node type"
    help: |
      - **any** - (*1-28 cores*) Use any available Owens node. This reduces the
        wait time as there are no node requirements.
      - **gpu** - (*1-28 cores*) Use an Owens node that has an [NVIDIA Tesla P100
        GPU] and loads the requested [CUDA] module. There are 160 of these nodes
        on Owens.
      - **hugemem** - (*48 cores*) Use an Owens node that has 1.5TB of
        available RAM as well as 48 cores. There are 16 of these nodes on
        Owens.
      - **debug** - (*1-28 cores*) For short sessions (= 1 hour) the debug queue
        will have the shortest wait time. This is only accessible during 8AM -
        6PM, Monday - Friday. There are 6 of these nodes on Owens.

      [NVIDIA Tesla P100 GPU]: http://www.nvidia.com/object/tesla-p100.html
      [CUDA]: https://developer.nvidia.com/cuda-zone
    options:
      - [
          "any",     "any",
          data-min-ppn-owens: 0,
          data-max-ppn-owens: 28,
          data-can-show-cuda-owens: false,
          data-min-ppn-pitzer: 0,
          data-max-ppn-pitzer: 40,
          data-can-show-cuda-pitzer: false
        ]
      - [
          "gpu",     "gpu",
          data-min-ppn-owens: 0,
          data-max-ppn-owens: 28,
          data-can-show-cuda-owens: true,
          data-min-ppn-pitzer: 0,
          data-max-ppn-pitzer: 40,
          data-can-show-cuda-pitzer: true,
        ]
      - [
          "hugemem", "hugemem",
          data-min-ppn-owens: 48,
          data-max-ppn-owens: 48,
          data-can-show-cuda-owens: false,
          data-min-ppn-pitzer: 80,
          data-max-ppn-pitzer: 80,
          data-can-show-cuda-pitzer: false
        ]
      - [
          "debug",   "debug",
          data-min-ppn-owens: 0,
          data-max-ppn-owens: 28,
          data-can-show-cuda-owens: false,
          data-min-ppn-pitzer: 0,
          data-max-ppn-pitzer: 40,
          data-can-show-cuda-pitzer: false
        ]
  version:
    widget: "select"
    label: "JupyterLab Version"
    options:
      - [ "2.1",  "app_jupyter/2.1.4" ]
      - [ "1.2",  "app_jupyter/1.2.16" ]
      - [ "0.35", "app_jupyter/0.35.6" ]
